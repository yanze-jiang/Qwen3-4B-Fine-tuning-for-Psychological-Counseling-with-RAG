# 基于心理咨询师数字孪生数据集的Qwen3-4B微调项目

## 📖 项目简介

本项目基于 Qwen3-4B 模型，使用 LoRA 技术对心理咨询师数字孪生数据集（PsyDTCorpus）进行微调，旨在构建专业的心理咨询对话模型。项目集成了 RAG（检索增强生成）技术，结合专业知识库（包含5本心理学专业书籍），可以检索相关专业知识来增强模型回复的专业性和准确性。项目包含完整的训练、评估和对比功能，适用于心理咨询领域的对话生成任务。

## 🎯 项目特点

- **基于 Qwen3-4B**：使用小体量的大语言模型
- **LoRA 微调**：采用参数高效微调技术，降低训练成本
- **专业数据集**：使用 PsyDTCorpus 心理咨询数据集
- **RAG 增强**：结合向量检索技术，从专业心理学知识库中检索相关信息
- **完整流程**：包含数据查看、模型训练、性能评估和对比分析

## 📁 项目结构

```
PsyDTCorpus/
├── model_origin/            # 原始模型相关
│   ├── Qwen3-4B/           # Qwen3-4B 模型文件
│   └── generate_text.py    # 文本生成脚本
├── lora/                    # LoRA 微调模块
│   ├── data/                # 数据集目录
│   │   ├── PsyDTCorpus/    # PsyDTCorpus 数据集
│   │   └── seeData.py      # 数据查看脚本
│   ├── training/            # 训练相关
│   │   ├── train.py        # 训练脚本
│   │   └── qwen-psy-trained/  # 训练后的模型
│   ├── benchmark/           # 基准测试
│   │   ├── model_original.py    # 原始模型测试
│   │   ├── model_trained.py     # 微调后模型测试
│   │   └── PsychCounsel-Bench.json  # 测试数据集
│   └── compare/             # 模型对比
│       ├── model_origin.py     # 原始模型推理
│       └── model_trained.py    # 微调后模型推理
└── rag/                     # RAG 增强模块
    ├── indexing.py         # 构建知识库向量索引
    ├── retrieval.py        # 知识检索器
    ├── compare_all.py      # 三种模型对比脚本
    ├── knowledge_base/     # 专业知识库（PDF 文件）
    │   ├── CCMD-3中国精神障碍分类与诊断标准.pdf
    │   ├── 中国心理学会临床与咨询心理学工作伦理守则解读.pdf
    │   ├── 国家职业资格培训教程 心理咨询师 三级.pdf
    │   ├── 心理咨询的理论与实务.pdf
    │   └── 认知疗法基础与应用.pdf
    └── vector_store/       # 向量存储目录
        └── psychology_db/  # FAISS 向量数据库
```

## 🔧 环境要求

### Python 版本
- Python 3.10+

### 主要依赖

基于代码分析，项目主要依赖以下包：

```bash
torch>=2.0.0                    # PyTorch深度学习框架
transformers>=4.51.0            # Hugging Face Transformers（需支持Qwen3）
datasets>=2.0.0                 # Hugging Face Datasets
peft>=0.3.0                     # Parameter-Efficient Fine-Tuning（LoRA）
accelerate>=0.20.0              # 分布式训练加速
tqdm                            # 进度条显示

# RAG 相关依赖（可选，如果使用 RAG 功能）
langchain>=0.1.0                # LangChain 框架
langchain-community>=0.0.20     # LangChain 社区组件
langchain-huggingface>=0.0.1    # LangChain HuggingFace 集成
faiss-cpu>=1.7.4                # FAISS 向量数据库（CPU 版本）
# faiss-gpu>=1.7.4              # 或使用 GPU 版本（如果有 GPU）
pypdf>=3.0.0                    # PDF 文件处理
```

**注意**：由于使用 Qwen3-4B 模型，需要 `transformers>=4.51.0` 版本支持。

### 安装依赖

```bash
# 基础依赖
pip install torch transformers datasets peft accelerate tqdm

# 如果需要使用CUDA，请安装对应版本的PyTorch
# 例如：pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 环境配置示例

```bash
# 创建虚拟环境（推荐）
conda create -n psydt python=3.10
conda activate psydt

# 安装依赖
pip install torch transformers>=4.51.0 datasets peft accelerate tqdm
```

## 📦 数据集准备

### 下载 PsyDTCorpus 数据集

数据集应放置在 `data/PsyDTCorpus/` 目录下，包含以下文件：
- `PsyDTCorpus_train_mulit_turn_packing.json` - 训练集
- `PsyDTCorpus_test_single_turn_split.json` - 测试集

### 数据集格式

数据集采用 OpenAI 格式，每个样本包含：
- `id`: 样本ID
- `normalizedTag`: 标签（如"婚恋"、"工作"等）
- `messages`: 对话消息列表，包含 system、user、assistant 角色

## 🚀 快速开始

### 1. 查看数据集

```bash
cd lora/data
python seeData.py
```

### 2. 训练模型

修改 `lora/training/train.py` 中的路径配置：

```python
# 修改模型路径
model_path = "/path/to/your/Qwen3-4B"

# 修改数据集路径
train_data = load_dataset("json", data_files="/path/to/train.json")
test_data = load_dataset("json", data_files="/path/to/test.json")
```

然后运行训练：

```bash
cd lora/training
python train.py
```

**训练配置**（基于代码）：

| 配置项               | 参数值                              |
| :------------------- | :---------------------------------- |
| **基座模型**         | Qwen3-4B                            |
| **微调方法**         | LoRA                                |
| `r`                  | 8（低秩矩阵的秩）                    |
| `lora_alpha`         | 32（LoRA 缩放因子）                 |
| `lora_dropout`       | 0.1（Dropout 率）                   |
| `target_modules`     | `["q_proj", "v_proj", "k_proj", "o_proj"]` |
| **训练轮数**         | 3 epochs                            |
| **学习率**           | 2e-4                                |
| **批次大小**         | 1（梯度累积步数：8，有效批次大小：8）|
| **最大序列长度**     | 384                                 |
| **优化器**           | AdamW                               |
| **混合精度**         | FP16                                |
| **评估步数**         | 每 200 步                           |
| **保存步数**         | 每 200 步（保留最佳 3 个检查点）    |
| **Warmup 步数**      | 100                                 |
| **数据加载工作线程** | 2                                   |

### 3. 模型评估

#### 评估原始模型（Baseline）

在运行前，修改 `lora/benchmark/model_original.py` 中的配置：

```python
BASE_MODEL_PATH = "/path/to/your/Qwen3-4B"
BENCHMARK_PATH = "/path/to/PsychCounsel-Bench.json"
```

运行评估：

```bash
cd lora/benchmark
python model_original.py
```

#### 评估微调后模型

修改 `lora/benchmark/model_trained.py` 中的配置：

```python
BASE_MODEL_PATH = "/path/to/your/Qwen3-4B"
LORA_PATH = "/path/to/lora/training/qwen-psy-trained"
BENCHMARK_PATH = "/path/to/PsychCounsel-Bench.json"
```

运行评估：

```bash
cd lora/benchmark
python model_trained.py
```

**评估说明**：
- 评估脚本支持三种提示词格式：专业心理咨询师格式、简单直接格式、对话格式
- 结果会保存为 JSON 文件，包含准确率和错误案例分析
- 自动选择最佳提示词格式

### 4. 模型对比

#### 原始模型推理

修改 `lora/compare/model_origin.py` 中的模型路径：

```python
model_path = "/path/to/your/Qwen3-4B"
```

运行推理：

```bash
cd lora/compare
python model_origin.py
```

#### 微调后模型推理

修改 `lora/compare/model_trained.py` 中的路径：

```python
model_path = "/path/to/your/Qwen3-4B"
lora_path = "/path/to/lora/training/qwen-psy-trained"
```

运行推理：

```bash
cd lora/compare
python model_trained.py
```

**对比功能**：
- 可以直观对比原始模型和微调后模型的回复差异
- 支持自定义测试问题

### 5. RAG 增强推理（检索增强生成）

本项目集成了 RAG（Retrieval-Augmented Generation）功能，可以从专业知识库中检索相关信息来增强模型回复的专业性和准确性。

#### 构建知识库索引

首先需要从 PDF 文件中构建向量索引：

```bash
cd rag
python indexing.py
```

**说明**：
- 脚本会自动扫描 `rag/knowledge_base/` 目录下的所有 PDF 文件
- 使用 `BAAI/bge-small-zh-v1.5` 作为嵌入模型
- 将文档切分为小块（chunk_size=300, overlap=40）适合 Qwen3-4B 模型
- 构建 FAISS 向量索引并保存到 `rag/vector_store/psychology_db/`

#### 使用 RAG 增强推理

```python
from rag.retrieval import PsyRetriever

# 初始化检索器
retriever = PsyRetriever()

# 检索相关上下文
query = "认知疗法的主要步骤"
context = retriever.get_relevant_context(query)

# 将检索到的上下文与用户问题结合，输入到模型
```

#### 运行完整对比测试

可以使用 `rag/compare_all.py` 脚本同时对比三种模型的回复：

```bash
cd rag
python compare_all.py
```

该脚本会自动加载原始模型、微调后模型和 RAG 增强模型，并对比它们对相同问题的回复，便于直观了解不同配置的效果。

**知识库包含的专业书籍**：
1. CCMD-3 中国精神障碍分类与诊断标准
2. 中国心理学会临床与咨询心理学工作伦理守则解读
3. 国家职业资格培训教程 心理咨询师 三级
4. 心理咨询的理论与实务
5. 认知疗法基础与应用（第2版）

**RAG 工作流程**：
1. **检索阶段**：根据用户问题，从专业知识库中检索最相关的文档片段
2. **增强阶段**：将检索到的上下文作为提示的一部分，输入到微调后的模型
3. **生成阶段**：模型基于检索到的专业知识和自身训练的知识生成回复

#### RAG 技术细节

**向量检索配置**：
- **嵌入模型**：`BAAI/bge-small-zh-v1.5`（中文优化的轻量级嵌入模型）
- **向量数据库**：FAISS（Facebook AI Similarity Search）
- **文档切分策略**：
  - `chunk_size=300`：每个文档块 300 字符，适合 Qwen3-4B 的上下文长度
  - `chunk_overlap=40`：块之间重叠 40 字符，保持语义连续性
- **检索策略**：相似度搜索（similarity_search），返回最相关的 1 个文档块

**优势**：
- ✅ **专业性增强**：直接从权威心理学书籍中检索相关知识
- ✅ **准确性提升**：结合检索到的专业内容，减少模型幻觉
- ✅ **知识更新**：可以通过更新知识库来补充最新的专业知识
- ✅ **可解释性**：可以追溯到检索到的具体文档来源

## 📊 模型配置

### LoRA 配置

```python
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                    # 低秩矩阵的秩
    lora_alpha=32,          # LoRA 缩放因子
    lora_dropout=0.1,       # Dropout 率
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    bias="none",
)
```

### 训练超参数

| 参数                         | 值      |
| :--------------------------- | :------ |
| `learning_rate`              | 2e-4    |
| `num_train_epochs`           | 3       |
| `per_device_train_batch_size`| 1       |
| `gradient_accumulation_steps`| 8       |
| `warmup_steps`               | 100     |
| `max_length`                 | 384     |
| `fp16`                       | True    |

## 📝 使用说明

### 修改路径配置

在使用前，请根据你的环境修改以下路径：

1. **模型路径**：在训练和推理脚本中修改 `model_path`
2. **数据集路径**：修改数据集文件的路径
3. **输出路径**：修改模型保存路径

### 自定义训练

你可以根据需要调整以下参数：
- LoRA 的 `r`、`alpha`、`dropout` 值
- 训练轮数、学习率、批次大小
- 最大序列长度

## 🔍 基准测试

项目使用 **PsychCounsel-Bench** 基准测试集（500 道心理学专业选择题）进行模型评估，支持多种提示词格式。

### 提示词格式说明

#### 1. 专业心理咨询师格式（推荐，准确率最高）

```python
你是一位专业的心理咨询师，请基于心理学专业知识选择最合适的答案。
问题：{题目内容}

选项：
A. {选项A内容}
B. {选项B内容}
C. {选项C内容}
D. {选项D内容}
E. {选项E内容}
请只输出选项字母（A/B/C/D/E），不要有任何其他文字。
```

**特点**：明确角色定位，要求基于专业心理学知识，指令简洁明确。

**示例**：

```
你是一位专业的心理咨询师，请基于心理学专业知识选择最合适的答案。
问题：An individual's self-esteem is most likely to improve when they credit their success to which of the following?

选项：
A. Factors within themselves
B. Factors outside themselves
C. Indirect factors
D. Random factors
E. Unstable factors

请只输出选项字母（A/B/C/D/E），不要有任何其他文字。
```

#### 2. 简单直接格式

```python
{题目内容}

A. {选项A内容}
B. {选项B内容}
C. {选项C内容}
D. {选项D内容}
E. {选项E内容}

请选择正确答案的字母：
```

**特点**：去除了角色设定和专业要求，直接呈现题目和选项，格式最简洁。

**示例**：

```
An individual's self-esteem is most likely to improve when they credit their success to which of the following?

A. Factors within themselves
B. Factors outside themselves
C. Indirect factors
D. Random factors
E. Unstable factors

请选择正确答案的字母：
```

#### 3. 对话格式

**System Message**：

```python
你是一位专业的心理咨询师，请根据心理学知识选择最合适的答案。
```

**User Message**：
```python
{题目内容}

选项：
A. {选项A内容}
B. {选项B内容}
C. {选项C内容}
D. {选项D内容}
E. {选项E内容}

请只输出选项字母：
```

**特点**：使用对话形式，包含 system 和 user 角色，更接近训练时的数据格式。

**示例**：

**System**:

```
你是一位专业的心理咨询师，请根据心理学知识选择最合适的答案。
```

**User**:

```
An individual's self-esteem is most likely to improve when they credit their success to which of the following?

选项：
A. Factors within themselves
B. Factors outside themselves
C. Indirect factors
D. Random factors
E. Unstable factors

请只输出选项字母：
```

### 评估结果

**不同格式下的表现对比**：

| 格式                 | 原始模型准确率 | 微调后模型准确率 | 说明                           |
| :------------------- | :------------- | :--------------- | :----------------------------- |
| **专业心理咨询师格式** | 80.60%         | 79.60%           | 准确率最高，**推荐使用**       |
| **简单直接格式**     | 46.20%         | 57.20%           | 中等准确率，微调后有明显提升   |
| **对话格式**         | 4.00%          | 2.20%            | 准确率较低，不适合选择题评估   |

**总体评估结果**：
- 原始模型最佳准确率：**80.60%**（专业心理咨询师格式）
- 微调后模型最佳准确率：**79.60%**（专业心理咨询师格式）
- 详细结果和对比分析请参考 [📊 对比分析](#-对比分析) 部分

评估结果会保存为 JSON 文件（`benchmark_test_results.json`），包含准确率、错误案例分析等详细信息。

## 📊 对比分析

### 一、LoRA 微调效果对比

本节对比原始 Qwen3 模型和基于 PsyDTCorpus 数据集微调后的模型表现。

#### 1.1 定性对话对比

**测试问题**：这段时间我不开心

#### 原始模型（without LoRA）

**模型信息**：

| 项目     | 值               |
| :------- | :--------------- |
| ✅ 状态  | 模型加载成功     |
| 📱 设备  | cuda:0           |
| 🔢 参数量| 4,022,468,096    |
| 💾 显存  | 7.49 GB          |

**模型回复**：

我能感受到你现在可能正经历一些困扰，情绪低落是人之常情。如果愿意的话，可以和我聊聊是什么让你感到不开心吗？有时候把心里的烦恼说出来，会感觉轻松一些。

如果你暂时不想多说，我也可以陪你一起做些轻松的事，比如听首音乐、聊聊天，或者一起散步。你并不孤单，我在这里陪着你。如果觉得压力太大，也可以考虑找信任的朋友倾诉，或者寻求专业的心理咨询帮助。

希望你能慢慢好起来，记得照顾好自己。如果需要的话，我随时都在。

**特点分析**：回复结构规范，提供了多种支持选项，但语气相对标准化，呈现一定的"心理咨询模板"特征。

#### 微调后模型（with LoRA）

**模型信息**：

| 项目     | 值               |
| :------- | :--------------- |
| ✅ 状态  | 微调模型加载成功 |
| 📱 设备  | cuda:0           |
| 🔢 参数量| 4,028,366,336    |
| 💾 显存  | 7.50 GB          |

**模型回复**：

我能感受到你现在心情不好，真的很抱歉听到你这样。有时候生活确实会给我们带来很多压力和困扰，让你感到难过和无助。你愿意和我聊聊发生了什么吗？我在这里陪着你，听你说说心事。

如果你不想马上说，也可以告诉我你想要什么样的支持：是想听听安慰的话，还是需要有人陪你理理头绪？不管怎样，我都会在这里支持你。有时候倾诉出来会感觉轻松一些，但如果你现在不想说，我理解，我们也可以先做点别的，比如聊聊你最近喜欢的事情，或者看看窗外的风景。

**特点分析**：共情表达更自然，主动询问用户需求并给予选择权，语气温和且贴近日常交流，在专业性和亲和力之间取得了更好的平衡。

#### 1.2 定量评估结果对比

我们使用 **PsychCounsel-Bench** 基准测试集（500 道心理学专业选择题）对模型进行了全面的定量评估，测试了三种不同的提示词格式。

**基准测试结果对比**：

| 提示词格式             | 原始模型准确率       | 微调后模型准确率     | 提升幅度      |
| :--------------------- | :------------------- | :------------------- | :------------ |
| **专业心理咨询师格式** | **80.60%** (403/500) | **79.60%** (398/500) | -1.00%        |
| **简单直接格式**       | 46.20% (231/500)     | **57.20%** (286/500) | **+11.00%** ⬆️ |
| **对话格式**           | 4.00% (20/500)       | 2.20% (11/500)       | -1.80%        |

#### 详细分析

1. **专业心理咨询师格式（最佳格式）**
   - 原始模型：80.60% (403/500)
   - 微调后模型：79.60% (398/500)
   - **分析**：两种模型在该格式下都表现优秀，准确率超过 79%。微调后模型略有下降（-1%），差异在统计误差范围内，基本保持了原有性能水平。

2. **简单直接格式**
   - 原始模型：46.20% (231/500)
   - 微调后模型：57.20% (286/500)
   - **分析**：微调后模型在该格式下表现**显著提升**（+11%），准确率提升了近 11 个百分点。这表明微调增强了模型在非专业提示词格式下的适应性，提高了鲁棒性。

3. **对话格式**
   - 原始模型：4.00% (20/500)
   - 微调后模型：2.20% (11/500)
   - **分析**：两种模型在该格式下准确率都很低，说明对话格式不适合用于多项选择题类型的基准测试。这类格式更适合对话生成任务。

#### 性能评估总结

- ✅ **整体性能**：微调后模型在最佳格式下保持了接近原始模型的高准确率（79.60%）
- ✅ **格式鲁棒性**：微调显著提升了模型在简单直接格式下的表现（+11%），增强了模型对不同提示词格式的适应性
- ✅ **性能评级**：根据评估标准，准确率超过 70% 为优秀级别，微调效果显著
- 📊 **提示词敏感性**：结果表明，专业心理咨询师格式最适合心理学知识问答任务，而对话格式不适合选择题类型的评估

#### 错误案例分析

从错误案例中观察到的主要问题类型：
1. **概念混淆**：对心理学专业概念（如 retroactive interference vs proactive interference）的理解偏差
2. **理论应用**：将理论应用到具体情境时的判断错误
3. **答案提取**：部分情况下模型生成了解释但未能正确提取选项字母

#### 1.3 LoRA 微调效果总结

通过对比分析，我们发现微调后的模型在以下几个方面表现出明显提升：

#### 1. **共情表达更自然**
- **微调后模型**：使用更贴近日常交流的共情表达（如"真的很抱歉听到你这样"），语气自然温和，能更好地营造安全、支持的对话氛围
- **原始模型**：共情表达准确但略显模板化，呈现出一定的"心理咨询话术"特征

#### 2. **尊重用户自主性**（关键专业指标）
- **微调后模型**：主动将对话方向的选择权交还给用户（如"你想要什么样的支持？"），体现了以用户为中心的心理咨询原则，这是专业度的重要体现
- **原始模型**：更倾向于温和引导，在给予用户控制感方面相对较弱

#### 3. **角色定位更平衡**
- **微调后模型**：更好地平衡了"专业咨询师"与"支持性陪伴者"的角色，既保持了专业性，又增强了情感温度
- **原始模型**：虽然规范性更强，但略显正式，亲和力稍弱

#### 4. **技术指标**
- 参数量增加：约 590 万个参数（LoRA 适配器）
- 显存占用：仅增加约 0.01 GB，几乎可以忽略不计
- 推理效率：无明显差异，保持高效

#### 综合结论

综合定性对话分析和定量基准测试结果，微调后的模型在多个维度表现出色：

**定性优势**：
- ✅ **更自然的共情表达**：对话更加真实、贴近日常交流
- ✅ **更好的用户自主性尊重**：符合心理咨询的核心原则
- ✅ **更平衡的角色定位**：专业性与亲和力并重

**定量表现**：
- ✅ **保持高准确率**：在最佳格式下维持了 79.60% 的准确率（接近原始模型的 80.60%）
- ✅ **增强格式鲁棒性**：在简单直接格式下准确率显著提升 11%（从 46.20% 提升至 57.20%）
- ✅ **极小的性能开销**：仅增加约 590 万参数（约 0.15%）和 0.01 GB 显存占用
- ✅ **性能评级优秀**：准确率超过 70%，达到优秀级别

**总体评价**：

基于 PsyDTCorpus 数据集的 LoRA 微调在**保持模型专业知识准确性的同时**，显著提升了模型在**心理咨询对话场景下的专业性和用户体验**。虽然在某些格式下准确率略有波动，但整体表现稳定，特别是在增强格式鲁棒性和提升对话自然度方面效果显著。

这表明该微调方案有效平衡了**专业性**（知识准确性）和**对话质量**（共情表达、用户自主性）两个维度，为构建专业的心理健康对话系统提供了可靠的技术基础。

---

### 二、RAG 增强效果对比

本节对比三种模型的完整表现：原始模型、LoRA 微调模型、以及结合 RAG 的微调模型。

#### 2.1 三种模型完整对比

**测试示例 1：情绪低落问题**

**测试问题**：我不开心，觉得生活没意思

**🟢 原始 Qwen3 回复**：

我能感受到你现在正经历一段艰难的时光，这种对生活的无力感确实会让人感到迷茫和痛苦。请记住，你的感受是真实且合理的，不必因此责怪自己。

在这样的时刻，也许我们可以一起尝试几个方向：

1. **觉察当下**：试着用手机记录三件今天发生的"微小好事"（哪怕只是阳光照进窗户），这能帮助我们重新连接生活中的积极面。
2. **身体信号**：如果你愿意，可以和我分享最近的身体感受（如失眠、食欲变化等）。这些生理反应往往是心理压力的信号灯。
3. **呼吸练习**：当我们感到沉重时，深呼吸能带来即时的舒缓。试试这个方法：吸气4秒→屏息4秒→呼气6秒，重复几次。
4. **存在感联结**：想象一个让你感到安全的人/事物（如一棵树、一块石头），用语言向它诉说此刻的心情。
5. **渐进式行动**：从最简单的开始，比如起身走动5分钟，或是给某人发一条简短的消息。

你愿意和我聊聊，最近有没有什么特别触动你的情绪事件吗？

**🔵 微调后 Qwen-Psy 回复**：

亲爱的朋友，听到你说感到不开心、生活没有意义，我非常理解你现在的心情。这种感觉就像被困在一个黑暗的房间里，连呼吸都变得沉重。请允许我给你一个温暖的拥抱（通过文字表达），告诉你：你并不孤单，我在这里陪伴你。

当我们遭遇情绪低谷时，往往需要先承认自己"此刻很痛苦"这个事实。你有没有注意到，在这种状态下，身体会有什么反应？比如心跳加速、胃部不适、手指颤抖...这些生理反应其实是在向我们传递信号，说明我们的身心正在经历着巨大的压力。

让我试试用一种新的方式来理解你的感受。想象一下，你站在一条河流边，河水代表着你此刻的情绪。当水势汹涌时，我们往往会恐慌，但如果我们能平静地观察水流的方向，反而能找到前进的路径。你愿意和我一起探索这条河吗？

最后想问问你，此刻你最需要的是什么？是一个可以倾诉的对象，是一些建议，还是一段安静的陪伴？无论你需要什么，我都愿意为你尽绵薄之力。

**🔥 微调 + RAG 回复**：

我能感受到你现在正经历着一段不太愉快的日子，这种对生活的麻木感确实让人感到沮丧和无助。请记住，你的感受是真实存在的，不需要为此感到羞愧或自责。

当我们陷入这样的情绪低谷时，往往是因为内心积压了太多未被处理的压力和困惑。你愿意和我聊聊最近有哪些事让你特别困扰吗？是不是遇到什么挫折，或者生活中出现了些让你感到不安的变化？有时候倾诉出来，反而能让我们看到问题的另一面。

如果你愿意的话，我们可以一起尝试找出这些负面情绪的根源。在等待专业帮助到来之前，你也可以试试这些温和的自我关怀：深呼吸时想象自己像给植物浇水一样滋养自己的心灵，每天给自己安排一件哪怕只是五分钟的小确幸（比如听喜欢的音乐、晒太阳），这些微小的努力都会让身心慢慢恢复活力。

你并不孤单，我在这里陪你一起寻找走出阴霾的办法。要不要我们先从梳理一下最近发生的事情开始？

**对比分析**：

| 维度 | 原始 Qwen3 | 微调后 Qwen-Psy | 微调 + RAG |
|:-----|:----------|:---------------|:----------|
| **共情表达** | 温和、理解，但略显模板化 | 深度共情，使用大量比喻和意象 | 专业且温和，结合理论知识 |
| **语言风格** | 结构化建议，逻辑清晰 | 心理咨询师风格，富有情感色彩 | 平衡专业性和亲和力 |
| **交互方式** | 提供具体方法，引导行动 | 使用隐喻、河流比喻等，更具探索性 | 结合专业知识和实用建议 |
| **专业程度** | 基础心理健康知识 | 体现心理咨询专业技巧 | 融合专业知识库内容 |

---

**测试示例 2：认知扭曲概念解释**

**测试问题**：什么是认知扭曲？

**🟢 原始 Qwen3 回复**：

认知扭曲（Cognitive Distortions）是指人们在处理信息时，由于情绪、经验、信念等因素的影响，产生的**非理性、不准确或偏颇的思维方式**。这些扭曲的思维模式会加剧负面情绪（如焦虑、抑郁），并可能导致不合理的判断或行为。它是**认知行为疗法（CBT）**中研究的核心内容之一。

**主要类型包括**：全有或全无思维、过度概括、灾难化、情绪推理、理智化、个人化、标签化、过度追求完美等。

**🔵 微调后 Qwen-Psy 回复**：

亲爱的朋友，谢谢你愿意探索内心世界并寻求理解。作为心理咨询师，我很高兴与你一起探讨这个重要的话题。

**认知扭曲（Cognitive Distortions）** 是指个体在感知现实、评价事件时出现的不合理思维倾向，这些思维偏差常常导致情绪痛苦和行为问题。它们像是一把双刃剑，既可以帮助我们快速做出反应，又可能让我们陷入负面情绪的漩涡。

**实践路径**：
1. **觉察训练**：记录触发扭曲的情境和想法
2. **批判性思维练习**：质疑想法的证据支持
3. **辩证检验法**：从不同角度看待问题
4. **现实验证技术**：评估最坏情况的可能性
5. **思维重构练习**：用具体事实替代绝对化陈述

认知行为疗法（CBT）是治疗认知扭曲的黄金标准，心理咨询师通常采用"苏格拉底式提问"帮助来访者检视思维。

**🔥 微调 + RAG 回复**：

亲爱的朋友，你提出的问题非常有意义。在心理健康领域，"认知扭曲"通常指人在情绪困扰或心理压力下，对自己、他人或事件产生不合理、偏颇的理解和判断，这种思维偏差会加剧负面情绪和行为反应。

从专业知识来看，精神疾病患者常出现**思维逻辑混乱**、**理解能力下降**、**记忆异常**等症状，这些都可能表现为认知扭曲的特征。例如：

1. **非黑即白思维**：把事情简单化为"全好/全坏"
2. **灾难化想象**：过度预估负面后果
3. **过度概括**：由单一事件推断出普遍结论
4. **事实扭曲**：歪曲客观现实

这些不合理思维像滤镜一样模糊了真实世界的清晰画面。认知扭曲本身并不是疾病，而是**隐藏在疾病背后的心理反应机制**。专业治疗（如认知行为疗法）正是通过识别和矫正这些思维偏差，帮助人们恢复理性认识和情感调节能力。

**对比分析**：

| 维度 | 原始 Qwen3 | 微调后 Qwen-Psy | 微调 + RAG |
|:-----|:----------|:---------------|:----------|
| **知识完整性** | 全面系统，8种类型详细说明 | 结构清晰，表格化呈现，更专业 | 结合专业知识库，引用临床特征 |
| **表达方式** | 学术化，直接给出定义和分类 | 咨询师风格，使用比喻和引导 | 专业术语与通俗解释结合 |
| **实用性** | 提供具体应对方法 | 提供实践路径和专业建议 | 强调专业治疗的重要性 |
| **专业深度** | 基础知识讲解 | 体现咨询技巧和干预方法 | 结合精神疾病诊断标准 |

---

**测试示例 3：CCMD-3 诊断标准**

**测试问题**：按照 CCMD-3 标准，抑郁发作需要持续多久？

**🟢 原始 Qwen3 回复**：

根据《中国精神障碍分类与诊断标准》第3版（CCMD-3），**抑郁发作的诊断需满足以下条件**：

1. **核心症状**：出现**至少2周以上的持续性情绪低落**
2. **症状严重程度**：在至少2周内，至少有2个主要抑郁症状持续存在
3. **排除其他原因**：需排除器质性疾病、药物因素等引起的抑郁样症状

**持续时间**：**2周以上**是诊断抑郁发作的关键时间标准。

**🔵 微调后 Qwen-Psy 回复**：

根据《中国精神疾病分类与诊断标准》第3版（CCMD-3），**抑郁发作的诊断需满足以下关键条件**：

**1. 症状标准**：患者在**连续2周以上**（通常为2周至2个月）出现抑郁核心症状，并符合至少4项相关症状。

**2. 严重程度分级**：

| 分级 | 症状持续时间 | 功能损害 |
|:-----|:------------|:--------|
| 轻度 | ≥2周 | 社会功能基本正常，自我照顾能力受损 |
| 中度 | ≥2周 | 社会功能明显受损，有轻度自责或自杀倾向 |
| 重度 | ≥2周 | 社会功能严重受损，有强烈自责、自杀意念或行为 |

**3. 排除标准**：需排除器质性疾病、药物滥用、混合状态等。

**重要提示**：CCMD-3标准是**临床诊断的重要参考**，但最终诊断需结合**全面评估**由**精神科医生或心理专科医师**完成。

**🔥 微调 + RAG 回复**：

亲爱的朋友，谢谢你提出这个问题。关于抑郁发作的持续时间，确实需要谨慎对待，因为这涉及到对心理健康状态的准确评估。

根据《中国精神疾病分类与诊断标准》第三版（CCMD-3），抑郁发作的核心症状包括显著的抑郁情绪、兴趣减退等，这些症状需要持续至少**两周以上**才能被确诊为抑郁发作。但需要注意的是，这个时间标准是临床诊断的基础，实际应用中还需要结合症状的严重程度、日常功能受损情况以及排除其他可能导致抑郁的原因等因素综合判断。

对于抑郁相关疾病的观察和诊断需要较长的随访时间（比如数年），这说明心理健康问题往往具有隐匿性和反复性。如果你或身边的人正在经历情绪低落、兴趣丧失等症状，建议尽早寻求专业精神科医生或心理治疗师的帮助，他们可以通过系统的评估来判断症状的性质和严重程度，并制定合适的干预方案。

**对比分析**：

| 维度 | 原始 Qwen3 | 微调后 Qwen-Psy | 微调 + RAG |
|:-----|:----------|:---------------|:----------|
| **专业性** | 准确给出 CCMD-3 标准，结构清晰 | 详细列出症状标准、分级和排除标准 | 结合专业知识库，强调临床实践 |
| **准确性** | 明确"2周以上"的时间标准 | 详细说明各类症状和分级 | 基于检索到的专业知识回答 |
| **表达方式** | 直接、学术化 | 咨询师风格，表格化呈现 | 温和、专业，结合心理关怀 |
| **实用性** | 提供建议和筛查工具 | 提供详细诊断标准和注意事项 | 强调专业评估的重要性 |

#### 2.2 RAG 增强效果总结

**总体对比**：

| 模型类型 | 优点 | 特点 | 适用场景 |
|:--------|:-----|:-----|:---------|
| **原始 Qwen3** | 知识全面、结构清晰、直接回答 | 语言略显模板化，缺乏专业技巧 | 通用问答 |
| **微调后 Qwen-Psy** | 深度共情、专业咨询技巧 | 心理咨询师风格，富有情感色彩 | 日常情感支持、咨询对话 |
| **微调 + RAG** | 结合专业知识库，回答更准确全面 | 平衡专业性和亲和力 | 专业概念解释、诊断标准查询 |

**应用建议**：

1. **日常情感支持**：推荐使用 **微调后 Qwen-Psy** 模型，其深度共情和咨询技巧更适合
2. **专业概念解释**：推荐使用 **微调 + RAG** 模型，能够结合专业知识库给出更准确的答案
3. **诊断标准查询**：推荐使用 **微调 + RAG** 模型，能够检索相关的诊断标准文档

**RAG 增强的优势**：

- ✅ **专业性增强**：直接从权威心理学书籍中检索相关知识
- ✅ **准确性提升**：结合检索到的专业内容，减少模型幻觉
- ✅ **知识更新**：可以通过更新知识库来补充最新的专业知识
- ✅ **可解释性**：可以追溯到检索到的具体文档来源

## ⚠️ 注意事项

1. **显存要求**：
   - 训练：建议使用至少 16GB 显存的 GPU（如 A100、V100、RTX 3090 等）
   - 推理：建议至少 8GB 显存
   - 使用 FP16 混合精度训练可以降低显存占用

2. **模型路径**：
   - 确保 Qwen3-4B 模型已正确下载到本地
   - 可以通过 ModelScope 或 Hugging Face 下载模型
   - 所有脚本中的路径都需要修改为实际路径

3. **数据集格式**：
   - 数据集必须符合 OpenAI 格式
   - 每个样本包含 `id`、`normalizedTag`、`messages` 字段
   - `messages` 中需要包含 `system`、`user`、`assistant` 角色

4. **依赖版本**：
   - **重要**：`transformers` 版本必须 >= 4.51.0（支持 Qwen3）
   - 较低版本会报错：`KeyError: 'qwen3'`

5. **训练建议**：
   - 训练过程中会每 200 步保存检查点
   - 最终模型保存在 `lora/training/qwen-psy-trained/` 目录
   - 可以使用 `lora/data/seeData.py` 先查看数据集结构

6. **推理参数**：
   - 非思考模式推荐参数：`Temperature=0.7`, `TopP=0.8`, `TopK=20`
   - 思考模式推荐参数：`Temperature=0.6`, `TopP=0.95`, `TopK=20`
   - 不要使用贪婪解码（greedy decoding），可能导致性能下降和无限重复

7. **RAG 功能使用**：
   - 首次使用需要运行 `rag/indexing.py` 构建向量索引
   - 确保 `rag/knowledge_base/` 目录下有 PDF 文件
   - 向量索引会保存在 `rag/vector_store/psychology_db/` 目录
   - 如果知识库更新，需要重新运行索引构建脚本
   - RAG 依赖（langchain, faiss 等）是可选的，仅在需要使用 RAG 功能时安装

## 📄 许可证

本项目遵循以下许可证：
- **项目代码**：Apache 2.0 License
- **基座模型 Qwen3-4B**：Apache 2.0 License（参考 [Qwen3-4B LICENSE](https://huggingface.co/Qwen/Qwen3-4B/blob/main/LICENSE)）
- **数据集 PsyDTCorpus**：请参考数据集原始许可证

## 👥 作者

- **Yanze Jiang**

## 🤝 贡献

欢迎提交 Issue 和 Pull Request 来帮助改进项目！

## 🙏 致谢

- 感谢 [Qwen](https://github.com/QwenLM/Qwen) 团队提供的优秀基座模型
- 感谢 PsyDTCorpus 数据集的贡献者
- 感谢 [PEFT](https://github.com/huggingface/peft) 项目提供的 LoRA 实现

## 📚 相关资源

- [Qwen 模型](https://github.com/QwenLM/Qwen)
- [PEFT 文档](https://huggingface.co/docs/peft)
- [Transformers 文档](https://huggingface.co/docs/transformers)

## 📮 联系方式

如有问题或建议，欢迎通过以下方式联系：
- 提交 GitHub Issue
- 发送邮件（请提供联系方式）

## 📊 项目特点详解

### 数据格式处理

项目使用 Qwen 对话格式进行数据预处理：

```python
def format_conversation(messages):
    """格式化对话为Qwen格式"""
    text = ""
    for msg in messages:
        if msg["role"] == "system":
            text += f"<|im_start|>system\n{msg['content']}<|im_end|>\n"
        elif msg["role"] == "user":
            text += f"<|im_start|>user\n{msg['content']}<|im_end|>\n"
        elif msg["role"] == "assistant":
            text += f"<|im_start|>assistant\n{msg['content']}<|im_end|>\n"
    return text
```

### LoRA 参数效率

使用 LoRA 技术显著降低可训练参数数量：
- 只训练注意力层（Q、K、V、O 投影层）的 LoRA 适配器
- 大部分模型参数冻结，只更新少量参数
- 训练后的模型文件大小远小于全量微调

### 评估指标

使用 PsychCounsel-Bench 进行多项选择题评估：
- 自动提取模型生成的答案选项（A/B/C/D/E）
- 支持多种提示词格式对比
- 输出详细准确率和错误案例分析

### RAG 检索增强生成

**工作原理**：
- 将专业知识库（PDF 文档）切分为小的文档块
- 使用嵌入模型将文档块转换为向量表示
- 将向量存储在 FAISS 向量数据库中
- 查询时，将用户问题转换为向量，检索最相似的文档块
- 将检索到的文档块作为上下文，与用户问题一起输入模型

**技术选型**：
- **LangChain**：提供文档加载、切分、向量化等完整的 RAG 流程
- **FAISS**：高效的向量相似度搜索库
- **BGE-small-zh-v1.5**：针对中文优化的轻量级嵌入模型

**适用场景**：
- 需要引用具体专业知识的问答
- 要求高准确性的专业咨询场景
- 需要可追溯信息来源的应用

---

**注意**：本项目仅用于科研和教育目的。模型生成的内容不应替代专业心理咨询服务。

