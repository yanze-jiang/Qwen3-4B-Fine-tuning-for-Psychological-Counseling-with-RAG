{
  "best_global_step": 1400,
  "best_metric": 3.5212301554565784e-06,
  "best_model_checkpoint": "./qwen-psy-training/checkpoint-1400",
  "epoch": 2.3529411764705883,
  "eval_steps": 200,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01680672268907563,
      "grad_norm": 1.3484374284744263,
      "learning_rate": 1.8e-05,
      "loss": 2.9926,
      "step": 10
    },
    {
      "epoch": 0.03361344537815126,
      "grad_norm": 1.1617189645767212,
      "learning_rate": 3.8e-05,
      "loss": 2.8001,
      "step": 20
    },
    {
      "epoch": 0.05042016806722689,
      "grad_norm": 1.4286110401153564,
      "learning_rate": 5.8e-05,
      "loss": 2.3575,
      "step": 30
    },
    {
      "epoch": 0.06722689075630252,
      "grad_norm": 4.85078763961792,
      "learning_rate": 7.800000000000001e-05,
      "loss": 1.5175,
      "step": 40
    },
    {
      "epoch": 0.08403361344537816,
      "grad_norm": 1.1591769456863403,
      "learning_rate": 9.8e-05,
      "loss": 0.4227,
      "step": 50
    },
    {
      "epoch": 0.10084033613445378,
      "grad_norm": 0.06181631237268448,
      "learning_rate": 0.000118,
      "loss": 0.0438,
      "step": 60
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 0.018734900280833244,
      "learning_rate": 0.000138,
      "loss": 0.0293,
      "step": 70
    },
    {
      "epoch": 0.13445378151260504,
      "grad_norm": 0.007493591867387295,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.0288,
      "step": 80
    },
    {
      "epoch": 0.15126050420168066,
      "grad_norm": 0.005210831295698881,
      "learning_rate": 0.00017800000000000002,
      "loss": 0.0286,
      "step": 90
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 0.005382501520216465,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.0284,
      "step": 100
    },
    {
      "epoch": 0.18487394957983194,
      "grad_norm": 0.0064970399253070354,
      "learning_rate": 0.00019893175074183977,
      "loss": 0.0283,
      "step": 110
    },
    {
      "epoch": 0.20168067226890757,
      "grad_norm": 0.01113952323794365,
      "learning_rate": 0.0001977448071216617,
      "loss": 0.0279,
      "step": 120
    },
    {
      "epoch": 0.2184873949579832,
      "grad_norm": 0.04453349858522415,
      "learning_rate": 0.00019655786350148368,
      "loss": 0.0266,
      "step": 130
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.7176058292388916,
      "learning_rate": 0.00019537091988130564,
      "loss": 0.0125,
      "step": 140
    },
    {
      "epoch": 0.25210084033613445,
      "grad_norm": 0.03612760081887245,
      "learning_rate": 0.0001944213649851632,
      "loss": 0.1522,
      "step": 150
    },
    {
      "epoch": 0.2689075630252101,
      "grad_norm": 0.009325633756816387,
      "learning_rate": 0.00019323442136498517,
      "loss": 0.0005,
      "step": 160
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.0036081590224057436,
      "learning_rate": 0.00019204747774480713,
      "loss": 0.0002,
      "step": 170
    },
    {
      "epoch": 0.3025210084033613,
      "grad_norm": 0.0018517803400754929,
      "learning_rate": 0.0001908605341246291,
      "loss": 0.0001,
      "step": 180
    },
    {
      "epoch": 0.31932773109243695,
      "grad_norm": 0.0012333744671195745,
      "learning_rate": 0.00018967359050445104,
      "loss": 0.0001,
      "step": 190
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 0.0009547944646328688,
      "learning_rate": 0.000188486646884273,
      "loss": 0.0001,
      "step": 200
    },
    {
      "epoch": 0.33613445378151263,
      "eval_loss": 4.7502817324129865e-05,
      "eval_runtime": 207.5069,
      "eval_samples_per_second": 20.775,
      "eval_steps_per_second": 20.775,
      "step": 200
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 0.0007945693796500564,
      "learning_rate": 0.00018729970326409497,
      "loss": 0.0,
      "step": 210
    },
    {
      "epoch": 0.3697478991596639,
      "grad_norm": 0.0006815232336521149,
      "learning_rate": 0.0001861127596439169,
      "loss": 0.0,
      "step": 220
    },
    {
      "epoch": 0.3865546218487395,
      "grad_norm": 0.0006081888568587601,
      "learning_rate": 0.00018492581602373888,
      "loss": 0.0,
      "step": 230
    },
    {
      "epoch": 0.40336134453781514,
      "grad_norm": 0.0005498163518495858,
      "learning_rate": 0.00018373887240356085,
      "loss": 0.0,
      "step": 240
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 0.0005017428775317967,
      "learning_rate": 0.0001825519287833828,
      "loss": 0.0,
      "step": 250
    },
    {
      "epoch": 0.4369747899159664,
      "grad_norm": 0.00046575249871239066,
      "learning_rate": 0.00018136498516320475,
      "loss": 0.0,
      "step": 260
    },
    {
      "epoch": 0.453781512605042,
      "grad_norm": 0.00042774449684657156,
      "learning_rate": 0.00018017804154302672,
      "loss": 0.0,
      "step": 270
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 0.0004060280043631792,
      "learning_rate": 0.00017899109792284868,
      "loss": 0.0,
      "step": 280
    },
    {
      "epoch": 0.48739495798319327,
      "grad_norm": 0.00037791996146552265,
      "learning_rate": 0.00017780415430267062,
      "loss": 0.0,
      "step": 290
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 0.00035631057107821107,
      "learning_rate": 0.0001766172106824926,
      "loss": 0.0,
      "step": 300
    },
    {
      "epoch": 0.5210084033613446,
      "grad_norm": 0.00033210593392141163,
      "learning_rate": 0.00017543026706231456,
      "loss": 0.0,
      "step": 310
    },
    {
      "epoch": 0.5378151260504201,
      "grad_norm": 0.00032032409217208624,
      "learning_rate": 0.0001742433234421365,
      "loss": 0.0,
      "step": 320
    },
    {
      "epoch": 0.5546218487394958,
      "grad_norm": 0.00030058209085837007,
      "learning_rate": 0.00017305637982195846,
      "loss": 0.0,
      "step": 330
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.00028596253832802176,
      "learning_rate": 0.00017186943620178043,
      "loss": 0.0,
      "step": 340
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.00027445508749224246,
      "learning_rate": 0.0001706824925816024,
      "loss": 0.0,
      "step": 350
    },
    {
      "epoch": 0.6050420168067226,
      "grad_norm": 0.0002604971523396671,
      "learning_rate": 0.00016949554896142434,
      "loss": 0.0,
      "step": 360
    },
    {
      "epoch": 0.6218487394957983,
      "grad_norm": 0.0002526413300074637,
      "learning_rate": 0.0001683086053412463,
      "loss": 0.0,
      "step": 370
    },
    {
      "epoch": 0.6386554621848739,
      "grad_norm": 0.00023919851810205728,
      "learning_rate": 0.00016712166172106827,
      "loss": 0.0,
      "step": 380
    },
    {
      "epoch": 0.6554621848739496,
      "grad_norm": 0.0002314384182682261,
      "learning_rate": 0.0001659347181008902,
      "loss": 0.0,
      "step": 390
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 0.00022238341625779867,
      "learning_rate": 0.00016474777448071217,
      "loss": 0.0,
      "step": 400
    },
    {
      "epoch": 0.6722689075630253,
      "eval_loss": 1.3755607142229564e-05,
      "eval_runtime": 206.8232,
      "eval_samples_per_second": 20.844,
      "eval_steps_per_second": 20.844,
      "step": 400
    },
    {
      "epoch": 0.6890756302521008,
      "grad_norm": 0.00021920706785749644,
      "learning_rate": 0.00016356083086053414,
      "loss": 0.0,
      "step": 410
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 0.00020765711087733507,
      "learning_rate": 0.00016237388724035608,
      "loss": 0.0,
      "step": 420
    },
    {
      "epoch": 0.7226890756302521,
      "grad_norm": 0.0002008080336963758,
      "learning_rate": 0.00016118694362017805,
      "loss": 0.0,
      "step": 430
    },
    {
      "epoch": 0.7394957983193278,
      "grad_norm": 0.0001915880711749196,
      "learning_rate": 0.00016,
      "loss": 0.0,
      "step": 440
    },
    {
      "epoch": 0.7563025210084033,
      "grad_norm": 0.0001881429343484342,
      "learning_rate": 0.00015881305637982195,
      "loss": 0.0,
      "step": 450
    },
    {
      "epoch": 0.773109243697479,
      "grad_norm": 0.00018357297813054174,
      "learning_rate": 0.00015762611275964392,
      "loss": 0.0,
      "step": 460
    },
    {
      "epoch": 0.7899159663865546,
      "grad_norm": 0.00017679893062449992,
      "learning_rate": 0.00015643916913946589,
      "loss": 0.0,
      "step": 470
    },
    {
      "epoch": 0.8067226890756303,
      "grad_norm": 0.0001732142991386354,
      "learning_rate": 0.00015525222551928785,
      "loss": 0.0,
      "step": 480
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 0.0001680815330473706,
      "learning_rate": 0.0001540652818991098,
      "loss": 0.0,
      "step": 490
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.00016202294500544667,
      "learning_rate": 0.00015287833827893176,
      "loss": 0.0,
      "step": 500
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.00015752692706882954,
      "learning_rate": 0.00015169139465875372,
      "loss": 0.0,
      "step": 510
    },
    {
      "epoch": 0.8739495798319328,
      "grad_norm": 0.0001522283419035375,
      "learning_rate": 0.00015050445103857566,
      "loss": 0.0,
      "step": 520
    },
    {
      "epoch": 0.8907563025210085,
      "grad_norm": 0.000149412895552814,
      "learning_rate": 0.00014931750741839763,
      "loss": 0.0,
      "step": 530
    },
    {
      "epoch": 0.907563025210084,
      "grad_norm": 0.0001448281982447952,
      "learning_rate": 0.0001481305637982196,
      "loss": 0.0,
      "step": 540
    },
    {
      "epoch": 0.9243697478991597,
      "grad_norm": 0.00014384875248651952,
      "learning_rate": 0.00014694362017804156,
      "loss": 0.0,
      "step": 550
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 0.00013967759150546044,
      "learning_rate": 0.0001457566765578635,
      "loss": 0.0,
      "step": 560
    },
    {
      "epoch": 0.957983193277311,
      "grad_norm": 0.0001366236829198897,
      "learning_rate": 0.00014456973293768547,
      "loss": 0.0,
      "step": 570
    },
    {
      "epoch": 0.9747899159663865,
      "grad_norm": 0.0001321095769526437,
      "learning_rate": 0.0001433827893175074,
      "loss": 0.0,
      "step": 580
    },
    {
      "epoch": 0.9915966386554622,
      "grad_norm": 0.0001296632399316877,
      "learning_rate": 0.00014219584569732938,
      "loss": 0.0,
      "step": 590
    },
    {
      "epoch": 1.0084033613445378,
      "grad_norm": 0.00012669670104514807,
      "learning_rate": 0.00014100890207715134,
      "loss": 0.0,
      "step": 600
    },
    {
      "epoch": 1.0084033613445378,
      "eval_loss": 8.242649528256152e-06,
      "eval_runtime": 209.8263,
      "eval_samples_per_second": 20.546,
      "eval_steps_per_second": 20.546,
      "step": 600
    },
    {
      "epoch": 1.0252100840336134,
      "grad_norm": 0.00012432600487954915,
      "learning_rate": 0.0001398219584569733,
      "loss": 0.0,
      "step": 610
    },
    {
      "epoch": 1.0420168067226891,
      "grad_norm": 0.00012034540850436315,
      "learning_rate": 0.00013863501483679527,
      "loss": 0.0,
      "step": 620
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 0.00011797060869866982,
      "learning_rate": 0.00013744807121661721,
      "loss": 0.0,
      "step": 630
    },
    {
      "epoch": 1.0756302521008403,
      "grad_norm": 0.00011517470557009801,
      "learning_rate": 0.00013626112759643918,
      "loss": 0.0,
      "step": 640
    },
    {
      "epoch": 1.092436974789916,
      "grad_norm": 0.00011485048889881,
      "learning_rate": 0.00013507418397626112,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 1.1092436974789917,
      "grad_norm": 0.00011133073712699115,
      "learning_rate": 0.0001338872403560831,
      "loss": 0.0,
      "step": 660
    },
    {
      "epoch": 1.1260504201680672,
      "grad_norm": 0.00010855319123947993,
      "learning_rate": 0.00013270029673590505,
      "loss": 0.0,
      "step": 670
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.00010711874347180128,
      "learning_rate": 0.00013151335311572702,
      "loss": 0.0,
      "step": 680
    },
    {
      "epoch": 1.1596638655462184,
      "grad_norm": 0.00010482849029358476,
      "learning_rate": 0.00013032640949554899,
      "loss": 0.0,
      "step": 690
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.00010443120845593512,
      "learning_rate": 0.00012913946587537093,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 1.1932773109243697,
      "grad_norm": 0.00010151119204238057,
      "learning_rate": 0.00012795252225519287,
      "loss": 0.0,
      "step": 710
    },
    {
      "epoch": 1.2100840336134453,
      "grad_norm": 0.00010108112473972142,
      "learning_rate": 0.00012676557863501483,
      "loss": 0.0,
      "step": 720
    },
    {
      "epoch": 1.226890756302521,
      "grad_norm": 9.836792742135003e-05,
      "learning_rate": 0.0001255786350148368,
      "loss": 0.0,
      "step": 730
    },
    {
      "epoch": 1.2436974789915967,
      "grad_norm": 9.614061855245382e-05,
      "learning_rate": 0.00012439169139465876,
      "loss": 0.0,
      "step": 740
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 9.46780783124268e-05,
      "learning_rate": 0.00012320474777448073,
      "loss": 0.0,
      "step": 750
    },
    {
      "epoch": 1.2773109243697478,
      "grad_norm": 9.365115693071857e-05,
      "learning_rate": 0.00012201780415430268,
      "loss": 0.0,
      "step": 760
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 9.21250248211436e-05,
      "learning_rate": 0.00012083086053412465,
      "loss": 0.0,
      "step": 770
    },
    {
      "epoch": 1.3109243697478992,
      "grad_norm": 9.131021943176165e-05,
      "learning_rate": 0.00011964391691394659,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 1.3277310924369747,
      "grad_norm": 9.074697300093248e-05,
      "learning_rate": 0.00011845697329376854,
      "loss": 0.0,
      "step": 790
    },
    {
      "epoch": 1.3445378151260505,
      "grad_norm": 8.750989945838228e-05,
      "learning_rate": 0.00011727002967359051,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 1.3445378151260505,
      "eval_loss": 5.893151410418795e-06,
      "eval_runtime": 208.6037,
      "eval_samples_per_second": 20.666,
      "eval_steps_per_second": 20.666,
      "step": 800
    },
    {
      "epoch": 1.361344537815126,
      "grad_norm": 8.721044287085533e-05,
      "learning_rate": 0.00011608308605341248,
      "loss": 0.0,
      "step": 810
    },
    {
      "epoch": 1.3781512605042017,
      "grad_norm": 8.484213321935385e-05,
      "learning_rate": 0.00011489614243323443,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 1.3949579831932772,
      "grad_norm": 8.551957580493763e-05,
      "learning_rate": 0.0001137091988130564,
      "loss": 0.0,
      "step": 830
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 8.340868953382596e-05,
      "learning_rate": 0.00011252225519287834,
      "loss": 0.0,
      "step": 840
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 8.213913679355755e-05,
      "learning_rate": 0.0001113353115727003,
      "loss": 0.0,
      "step": 850
    },
    {
      "epoch": 1.4453781512605042,
      "grad_norm": 8.077610982581973e-05,
      "learning_rate": 0.00011014836795252225,
      "loss": 0.0,
      "step": 860
    },
    {
      "epoch": 1.46218487394958,
      "grad_norm": 7.900057971710339e-05,
      "learning_rate": 0.00010896142433234422,
      "loss": 0.0,
      "step": 870
    },
    {
      "epoch": 1.4789915966386555,
      "grad_norm": 7.858295430196449e-05,
      "learning_rate": 0.00010777448071216619,
      "loss": 0.0,
      "step": 880
    },
    {
      "epoch": 1.495798319327731,
      "grad_norm": 7.895629823906347e-05,
      "learning_rate": 0.00010658753709198814,
      "loss": 0.0,
      "step": 890
    },
    {
      "epoch": 1.5126050420168067,
      "grad_norm": 7.737796113360673e-05,
      "learning_rate": 0.00010540059347181011,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 7.721663132542744e-05,
      "learning_rate": 0.00010421364985163205,
      "loss": 0.0,
      "step": 910
    },
    {
      "epoch": 1.5462184873949578,
      "grad_norm": 7.542136881966144e-05,
      "learning_rate": 0.00010302670623145401,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 1.5630252100840336,
      "grad_norm": 7.40423784009181e-05,
      "learning_rate": 0.00010183976261127597,
      "loss": 0.0,
      "step": 930
    },
    {
      "epoch": 1.5798319327731094,
      "grad_norm": 7.442006608471274e-05,
      "learning_rate": 0.00010065281899109793,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 1.596638655462185,
      "grad_norm": 7.306837505893782e-05,
      "learning_rate": 9.946587537091989e-05,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 1.6134453781512605,
      "grad_norm": 7.202236884040758e-05,
      "learning_rate": 9.827893175074184e-05,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 1.6302521008403361,
      "grad_norm": 7.114026084309444e-05,
      "learning_rate": 9.70919881305638e-05,
      "loss": 0.0,
      "step": 970
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 7.077595364535227e-05,
      "learning_rate": 9.590504451038577e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 1.6638655462184873,
      "grad_norm": 6.936582212802023e-05,
      "learning_rate": 9.471810089020771e-05,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 6.819448026362807e-05,
      "learning_rate": 9.353115727002968e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 1.680672268907563,
      "eval_loss": 4.6846903387631755e-06,
      "eval_runtime": 208.7923,
      "eval_samples_per_second": 20.647,
      "eval_steps_per_second": 20.647,
      "step": 1000
    },
    {
      "epoch": 1.6974789915966386,
      "grad_norm": 6.877839041408151e-05,
      "learning_rate": 9.234421364985164e-05,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 6.819195550633594e-05,
      "learning_rate": 9.11572700296736e-05,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 1.73109243697479,
      "grad_norm": 6.697772914776579e-05,
      "learning_rate": 8.997032640949555e-05,
      "loss": 0.0,
      "step": 1030
    },
    {
      "epoch": 1.7478991596638656,
      "grad_norm": 6.587292591575533e-05,
      "learning_rate": 8.878338278931752e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 6.527260120492429e-05,
      "learning_rate": 8.759643916913947e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 1.7815126050420167,
      "grad_norm": 6.457748531829566e-05,
      "learning_rate": 8.640949554896142e-05,
      "loss": 0.0,
      "step": 1060
    },
    {
      "epoch": 1.7983193277310925,
      "grad_norm": 6.354718061629683e-05,
      "learning_rate": 8.522255192878339e-05,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 1.815126050420168,
      "grad_norm": 6.453721289290115e-05,
      "learning_rate": 8.403560830860534e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 1.8319327731092439,
      "grad_norm": 6.299193046288565e-05,
      "learning_rate": 8.284866468842731e-05,
      "loss": 0.0,
      "step": 1090
    },
    {
      "epoch": 1.8487394957983194,
      "grad_norm": 6.180947821121663e-05,
      "learning_rate": 8.166172106824926e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 1.865546218487395,
      "grad_norm": 6.217642658157274e-05,
      "learning_rate": 8.047477744807123e-05,
      "loss": 0.0,
      "step": 1110
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 6.202766235219315e-05,
      "learning_rate": 7.928783382789318e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 1.8991596638655461,
      "grad_norm": 6.120830221334472e-05,
      "learning_rate": 7.810089020771513e-05,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 1.9159663865546217,
      "grad_norm": 6.030299118719995e-05,
      "learning_rate": 7.69139465875371e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 1.9327731092436975,
      "grad_norm": 5.932654676144011e-05,
      "learning_rate": 7.572700296735905e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 1.949579831932773,
      "grad_norm": 5.878807860426605e-05,
      "learning_rate": 7.4540059347181e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 1.9663865546218489,
      "grad_norm": 5.945221346337348e-05,
      "learning_rate": 7.335311572700297e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 1.9831932773109244,
      "grad_norm": 5.857699943589978e-05,
      "learning_rate": 7.216617210682493e-05,
      "loss": 0.0,
      "step": 1180
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.801280349260196e-05,
      "learning_rate": 7.097922848664689e-05,
      "loss": 0.0,
      "step": 1190
    },
    {
      "epoch": 2.0168067226890756,
      "grad_norm": 5.745228554587811e-05,
      "learning_rate": 6.979228486646885e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 2.0168067226890756,
      "eval_loss": 3.9614101297047455e-06,
      "eval_runtime": 208.5226,
      "eval_samples_per_second": 20.674,
      "eval_steps_per_second": 20.674,
      "step": 1200
    },
    {
      "epoch": 2.033613445378151,
      "grad_norm": 5.670856626238674e-05,
      "learning_rate": 6.86053412462908e-05,
      "loss": 0.0,
      "step": 1210
    },
    {
      "epoch": 2.0504201680672267,
      "grad_norm": 5.691797923645936e-05,
      "learning_rate": 6.741839762611276e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 2.0672268907563027,
      "grad_norm": 5.662710827891715e-05,
      "learning_rate": 6.623145400593472e-05,
      "loss": 0.0,
      "step": 1230
    },
    {
      "epoch": 2.0840336134453783,
      "grad_norm": 5.6941262300824746e-05,
      "learning_rate": 6.504451038575668e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 5.5024171160766855e-05,
      "learning_rate": 6.385756676557864e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 5.588087151409127e-05,
      "learning_rate": 6.26706231454006e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 2.134453781512605,
      "grad_norm": 5.454085840028711e-05,
      "learning_rate": 6.148367952522256e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 2.1512605042016806,
      "grad_norm": 5.377853085519746e-05,
      "learning_rate": 6.029673590504451e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 2.168067226890756,
      "grad_norm": 5.368017082219012e-05,
      "learning_rate": 5.910979228486647e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 2.184873949579832,
      "grad_norm": 5.357105328585021e-05,
      "learning_rate": 5.7922848664688436e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 2.2016806722689077,
      "grad_norm": 5.350344144972041e-05,
      "learning_rate": 5.673590504451038e-05,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 2.2184873949579833,
      "grad_norm": 5.265090294415131e-05,
      "learning_rate": 5.554896142433235e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 5.30204561073333e-05,
      "learning_rate": 5.436201780415431e-05,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 2.2521008403361344,
      "grad_norm": 5.2528437663568184e-05,
      "learning_rate": 5.317507418397626e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 2.26890756302521,
      "grad_norm": 5.2192717703292146e-05,
      "learning_rate": 5.198813056379822e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 5.173803583602421e-05,
      "learning_rate": 5.080118694362018e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 2.302521008403361,
      "grad_norm": 5.140384746482596e-05,
      "learning_rate": 4.961424332344214e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 2.3193277310924367,
      "grad_norm": 5.1328785048099235e-05,
      "learning_rate": 4.8427299703264094e-05,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 2.3361344537815127,
      "grad_norm": 5.109964695293456e-05,
      "learning_rate": 4.724035608308606e-05,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 5.093619984108955e-05,
      "learning_rate": 4.605341246290801e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 2.3529411764705883,
      "eval_loss": 3.5212301554565784e-06,
      "eval_runtime": 206.9867,
      "eval_samples_per_second": 20.827,
      "eval_steps_per_second": 20.827,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1785,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.39142517096448e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
